{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "from matplotlib import pyplot\n",
    "import matplotlib\n",
    "import pandas\n",
    "from pony import orm\n",
    "from IPython import display\n",
    "import jinja2\n",
    "import db\n",
    "import seaborn\n",
    "import os\n",
    "import numpy as np\n",
    "import warnings\n",
    "import pathlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('data')\n",
    "db.use_db(str(pathlib.Path.cwd() / 'course.sqlite'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "exam_id = os.environ['EXAM_ID']\n",
    "\n",
    "full_scores = db.full_exam_data(exam_id)\n",
    "# Full exam data has multilevel columns (includes detailed feedback), we flatten them out first.\n",
    "problem_scores = full_scores.iloc[:, full_scores.columns.get_level_values(1) == 'total']\n",
    "problem_scores.columns = problem_scores.columns.get_level_values(0)\n",
    "# Exclude empty columns from statistics\n",
    "problem_scores = problem_scores.loc[:, ~(problem_scores == 0).all()]\n",
    "\n",
    "with orm.db_session:\n",
    "    display.display_html(display.HTML('<h1>Statistics for {}<h1>'.format(db.Exam[exam_id].name)))\n",
    "\n",
    "warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## At a glance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "seaborn.set()\n",
    "seaborn.set_context(\"notebook\", font_scale=1.5, rc={\"lines.linewidth\": 2.5})\n",
    "\n",
    "cm = matplotlib.cm.magma\n",
    "# define the bins and normalize\n",
    "bounds = np.linspace(0, 1, 21)\n",
    "norm = matplotlib.colors.BoundaryNorm(bounds, cm.N)\n",
    "\n",
    "\n",
    "vals = [problem_scores[i].value_counts(normalize=True).sort_index().cumsum() for i in problem_scores]\n",
    "data = np.array([(-i, upper-lower, lower, num/val.index[-1]) for i, val in enumerate(vals) \n",
    "                 for num, upper, lower in zip(val.index, val.data, [0] + list(val.data[:-1]))]).T\n",
    "fig = pyplot.figure(figsize=(12, 9))\n",
    "ax = fig.add_subplot(1, 1, 1)\n",
    "ax.barh(data[0], data[1], data[3]/2 + .1, data[2], color=cm(norm(data[3])), align='edge')\n",
    "ax.set_yticks(np.arange(0, -len(problem_scores.columns), -1));\n",
    "ax.set_yticklabels(problem_scores.columns);\n",
    "ax.set_xlabel('percentile')\n",
    "ax.set_xlim(-0.025, 1.025)\n",
    "sm = matplotlib.cm.ScalarMappable(cmap=cm, norm=norm)\n",
    "sm._A = []\n",
    "colorbar = fig.colorbar(sm)\n",
    "colorbar.set_ticks(np.linspace(0, 1, 11))\n",
    "colorbar.set_label('score percentage')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correlations between different problems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "problem_scores.fillna(0).corr().round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lenghty description of all possible feedback options and how often they were received"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "feedback_template = jinja2.Template(\"\"\"<ul>\n",
    "{% for fo in feedback_options %}\n",
    "<li> {{ fo.text }}: {{ fo.description }} </li>\n",
    "{% endfor %}\n",
    "</ul>\n",
    "\"\"\")\n",
    "\n",
    "stats = ''\n",
    "\n",
    "for problem in db.Exam[exam_id].problems.order_by(lambda p: p.name):\n",
    "    if not orm.max(problem.feedback_options.score, default=0):\n",
    "        continue\n",
    "    df = pandas.DataFrame({fo.text: (fo.solutions.count(), fo.score) \n",
    "                           for fo in problem.feedback_options if fo.solutions.count()}, \n",
    "                          index=['amount', 'score']).T.fillna(0).astype(int)\n",
    "    df.index.name = \"Feedback\"\n",
    "    stats += '<h3>' + problem.name + '</h3>'\n",
    "    stats += '<h4>Feedback frequencies and scores</h4>'\n",
    "    stats += df._repr_html_()\n",
    "    stats += '<hr><h4>Descriptions</h4>'\n",
    "    stats += feedback_template.render(feedback_options=(fo for fo in problem.feedback_options\n",
    "                                                        if fo.solutions.count()))\n",
    "\n",
    "\n",
    "stats = display.HTML(stats)\n",
    "stats"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
